{"spans": [{"trace_id": "EC2XSeHX0wHsll7LF792oQ==", "span_id": "g7unyExl7LQ=", "trace_state": "", "parent_span_id": "", "name": "Crew.kickoff", "start_time_unix_nano": 1752420536740573000, "end_time_unix_nano": 1752420536763339000, "attributes": {"process": "\"sequential\"", "tasks": "\"[{'agent': '\\\"Lead Scraper - Target: {max_leads} leads\\\"\\\\n', 'description': '\\\"TARGET: Generate EXACTLY {max_leads} leads using the user\\\\'s search strategy\\\\nYour mission is to find and extract exactly {max_leads} high-quality leads using the search strategy provided by the user. Focus on prospects that match the user\\\\'s search criteria and target audience.\\\\nUser Input: Search Strategy: {domain} Target Clients: {target_clients} Campaign Agenda: {campaign_agenda} Maximum Leads: {max_leads} (THIS IS YOUR TARGET - DO NOT STOP UNTIL YOU REACH THIS NUMBER) Search Depth: {search_depth}\\\\nCRITICAL REQUIREMENTS: - You MUST generate exactly {max_leads} leads - Do not stop until you have exactly {max_leads} leads - Track your progress and report how many leads you have found - Use the search strategy provided by the user - Use multiple search approaches to reach the target\\\\nSEARCH APPROACHES (Use these systematically with the user\\\\'s search strategy): 1. Direct Search: Use the exact search strategy provided by the user 2. Keyword Variations: Modify the search strategy with different keywords 3. Industry-Specific: Add industry terms to the search strategy 4. Location-Based: Add location terms to the search strategy 5. Job Title Focus: Add job title terms to the search strategy 6. Company Focus: Add company-specific terms to the search strategy\\\\nEXECUTION PLAN: 1. Start with the user\\\\'s search strategy, extract leads, count them 2. If you haven\\\\'t reached {max_leads}, try keyword variations 3. Continue through all approaches until you have exactly {max_leads} leads 4. After each approach, report: \\\"Found X leads so far, need Y more\\\" 5. Do not stop until you have exactly {max_leads} leads\\\\nOUTPUT FORMAT: Return a JSON array with exactly {max_leads} lead objects, each containing: - name: Lead\\\\'s full name - company: Company name - title: Job title - linkedin: LinkedIn profile URL (if available) - email: (leave empty, will be filled by email finder)\\\\nREMEMBER: Your target is {max_leads} leads. Do not stop until you reach this number. \\\"\\\\n', 'async_execution': False, 'expected_output': '\\\"JSON array of lead objects with name, email, company, title, and linkedin fields\\\"\\\\n', 'human_input': False, 'tools': [SerperDevTool(name='Search the internet with Serper', description=\\\"Tool Name: Search the internet with Serper\\\\nTool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\\\\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\\\", env_vars=[EnvVar(name='SERPER_API_KEY', description='API key for Serper', required=True, default=None)], args_schema=<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, base_url='https://google.serper.dev', n_results=10, save_file=False, search_type='search', country='', location='', locale='')], 'output_file': 'output/scrape_leads.json\\\\n'}, {'agent': '\\\"Email Address Finder\\\"\\\\n', 'description': '\\\"Find email addresses for leads using multiple search strategies and sources. For each lead without an email address, search across various online sources to locate their email.\\\\nSEARCH STRATEGIES: 1. Company website search: \\\"[Name] [Company] email\\\" or \\\"[Name] @ [Company]\\\" 2. Professional directories: Search for the person on professional platforms 3. Social media: Look for contact information on LinkedIn, Twitter, etc. 4. Industry directories: Search industry-specific directories and databases 5. Conference/event websites: Look for speaker or attendee lists 6. Press releases: Search for company press releases mentioning the person 7. GitHub/technical profiles: For tech professionals, check GitHub profiles 8. If email is not found, try to find the email address of the company by searching the company name of the lead\\\\nINPUT: JSON array of leads with name, company, title, and linkedin fields (email field may be empty)\\\\nOUTPUT: JSON array of leads with email addresses found and added to each lead object. If no email is found for a lead, keep the email field empty or null.\\\\nIMPORTANT: Use \\\\'Search the internet with Serper\\\\' tool to perform searches. IMPORTANT: Focus on finding professional email addresses (company emails preferred over personal). IMPORTANT: Verify email format and validity before including in results. \\\"\\\\n', 'async_execution': False, 'expected_output': '\\\"JSON array of leads with email addresses found and added to each lead object\\\"\\\\n', 'human_input': False, 'tools': [SerperDevTool(name='Search the internet with Serper', description=\\\"Tool Name: Search the internet with Serper\\\\nTool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\\\\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\\\", env_vars=[EnvVar(name='SERPER_API_KEY', description='API key for Serper', required=True, default=None)], args_schema=<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, base_url='https://google.serper.dev', n_results=10, save_file=False, search_type='search', country='', location='', locale='')], 'output_file': 'output/find_lead_emails.json\\\\n'}, {'agent': '\\\"Lead Email Validator\\\"\\\\n', 'description': '\\\"Validate all lead email addresses for deliverability, spam traps, and quality using EmailListVerify API.\\\\nINPUT: JSON array of leads with email addresses\\\\nPROCESS: 1. Extract all email addresses from the leads array 2. Use the email_validator tool with the \\\\'emails\\\\' parameter in JSON format:\\\\n   {\\\\n     \\\\\\\\\\\"emails\\\\\\\\\\\": \\\\\\\\\\\"[\\\\\\\\\\\"email1@example.com\\\\\\\\\\\", \\\\\\\\\\\"email2@example.com\\\\\\\\\\\"]\\\\\\\\\\\"\\\\n   }\\\\n3. Process the validation results and update each lead with validation status 4. Filter out invalid emails and create a summary\\\\nIMPORTANT: Use the email_validator tool with ONLY the \\\\'emails\\\\' parameter. IMPORTANT: The tool expects a JSON string array of email addresses. IMPORTANT: Wait for the tool response before proceeding. IMPORTANT: Handle both valid and invalid email results properly. \\\"\\\\n', 'async_execution': False, 'expected_output': '\\\"JSON object with validated leads array and validation summary. Include all the fields you have in the data.\\\"\\\\n', 'human_input': False, 'tools': [Tool(name='email_validator', description='Tool Name: email_validator\\\\nTool Arguments: {\\\\'emails\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: \\\\n    Validate email addresses for deliverability and spam issues using EmailListVerify API.\\\\n    \\\\n    Args:\\\\n        emails: JSON string of email addresses for validation\\\\n        \\\\n    Example:\\\\n        ```json\\\\n        {\\\\n            \\\"emails\\\": \\\"[\\\"john@example.com\\\", \\\"jane@example.com\\\"]\\\"\\\\n        }\\\\n        ```\\\\n        \\\\n        Or for single email:\\\\n        ```json\\\\n        {\\\\n            \\\"emails\\\": \\\"[\\\"john.doe@example.com\\\"]\\\"\\\\n        }\\\\n        ```\\\\n    ', env_vars=[], args_schema=<class 'abc.Email_Validator'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, func=<function validate_email at 0x13012b2e0>)], 'output_file': 'output/validate_lead_emails.json\\\\n'}, {'agent': '\\\"Data Storage Specialist\\\"\\\\n', 'description': '\\\"CRITICAL: You MUST use the provided tool to save data. DO NOT create fake URLs or pretend to save data.\\\\nSave leads and validated email data created by your previous agents to Google Sheets. Clean the data before saving it to Google Sheets. You can include all the data when you save but mention email is valid/invalid in the data. Include all possible fields you have in the data.\\\\nUser Input: User ID: {user_id} Username: {username} Email: {email} Google Authenticated: {google_authenticated}\\\\nAVAILABLE TOOL (YOU MUST USE THIS): - google_sheets_saver: Use this tool to save lead data to Google Sheets\\\\nMANDATORY STEPS (DO NOT SKIP ANY): 1. Fetch the data from the previous agents (leads and validated email data) 2. Include all the fields you have in the data. 3. Clean the data 4. MANDATORY: Use the google_sheets_saver tool to save leads data in this format:\\\\n   {\\\\n     \\\"data\\\": \\\"[{\\\\\\\\\\\"name\\\\\\\\\\\": \\\\\\\\\\\"John Doe\\\\\\\\\\\", \\\\\\\\\\\"email\\\\\\\\\\\": \\\\\\\\\\\"john@example.com\\\\\\\\\\\", \\\\\\\\\\\"company\\\\\\\\\\\": \\\\\\\\\\\"Tech Corp\\\\\\\\\\\"}]\\\",\\\\n     \\\"sheet_name\\\": \\\"Leads\\\",\\\\n     \\\"user_id\\\": \\\"{user_id}\\\"\\\\n   }\\\\n   CRITICAL: You MUST call this tool and wait for its response. Do not create fake URLs.\\\\n   CRITICAL: Use the user_id from the input data to ensure data is saved to the correct user\\\\'s account. \\\\n   CRITICAL: The tool will automatically create a new spreadsheet for each save operation.\\\\n   CRITICAL: The tool parameters are: data, sheet_name, user_id (in that order).\\\\n   CRITICAL: Wait for the tool to return the actual spreadsheet URL before proceeding.\\\\n4. Return ONLY the actual file URL returned by the tool in JSON format\\\\nCRITICAL RULES: - NEVER create fake URLs or pretend to save data - ALWAYS use the google_sheets_saver tool for Google Sheets - ALWAYS wait for the tool response before proceeding - ONLY return URLs that come from the tool responses - If the tool fails, report the error, do not create fake success - Do not make up or generate fake spreadsheet URLs\\\"\\\\n', 'async_execution': False, 'expected_output': '\\\"JSON object with ONLY the actual file URL returned by the google_sheets_saver tool.  Example: {\\\\\\\\\\\"sheets_url\\\\\\\\\\\": \\\\\\\\\\\"https://docs.google.com/spreadsheets/d/...\\\\\\\\\\\"} DO NOT create fake URLs. Only return URLs that come from the tool responses.\\\"\\\\n', 'human_input': False, 'tools': [Tool(name='google_sheets_saver', description='Tool Name: google_sheets_saver\\\\nTool Arguments: {\\\\'data\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}, \\\\'sheet_name\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}, \\\\'user_id\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: \\\\n    Save lead data and campaign information to user\\\\'s Google Sheets.\\\\n    \\\\n    Args:\\\\n        data: JSON string containing data to save\\\\n        sheet_name: Name of the sheet to write to (default: \\\"Leads\\\")\\\\n        user_id: User ID for authentication (default: \\\"default\\\")\\\\n        \\\\n    Example:\\\\n        ```json\\\\n        {\\\\n            \\\"data\\\": \\\"[{\\\"name\\\": \\\"John Doe\\\", \\\"email\\\": \\\"john@example.com\\\", \\\"company\\\": \\\"Tech Corp\\\"}]\\\",\\\\n            \\\"sheet_name\\\": \\\"Leads\\\",\\\\n            \\\"user_id\\\": \\\"user123\\\"\\\\n        }\\\\n        ```\\\\n    ', env_vars=[], args_schema=<class 'abc.Google_Sheets_Saver'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, func=<function save_to_google_sheets at 0x130852de0>)], 'output_file': 'output/save_data.json\\\\n'}]\"", "share_crew": "false", "short_term_memory": "{\"embedder_config\": null, \"crew\": null, \"storage\": \"<crewai.memory.storage.rag_storage.RAGStorage object at 0x13343b080>\"}", "id": "\"19c899f5-8042-493a-9e7c-36f113d74e2b\"", "cache": "true", "verbose": "true", "execution_logs": "\"[]\"", "long_term_memory": "{\"embedder_config\": null, \"crew\": null, \"storage\": \"<crewai.memory.storage.ltm_sqlite_storage.LTMSQLiteStorage object at 0x1328b32c0>\"}", "embedder": "{\"provider\": \"openai\", \"config\": {\"api_key\": \"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\", \"model\": \"text-embedding-3-small\"}}", "planning": "false", "security_config": "{\"version\": \"1.0.0\", \"fingerprint\": {\"uuid_str\": \"96a57e35-35e6-4415-adf3-21743fadb42e\", \"created_at\": \"2025-07-13 20:58:56.458328\", \"metadata\": {}}}", "before_kickoff_callbacks": "\"[]\"", "mlflow.traceRequestId": "\"05ff1809000d4a78a8b1b9a8a0044926\"", "entity_memory": "{\"embedder_config\": null, \"crew\": null, \"storage\": \"<crewai.memory.storage.rag_storage.RAGStorage object at 0x133f2fb90>\"}", "after_kickoff_callbacks": "\"[<function crew.<locals>.wrapper.<locals>.callback_wrapper.<locals>.wrapper at 0x1344f9b20>]\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"inputs\": {\"search_strategy\": \"doctors currently working in hospitals in US\", \"target_clients\": [\"ceo\", \"founder\", \"president\", \"director\", \"doctor\"], \"campaign_agenda\": \"book a demo\", \"max_leads\": 50, \"search_depth\": 3, \"current_date\": \"2025-07-13 20:58:56.457362\", \"user_id\": \"b501f485-02c3-4cef-a3ef-e394e6e7af4d\", \"username\": \"geethika\", \"email\": \"geethu608@gmail.com\", \"google_authenticated\": true, \"google_email\": \"geethu608@gmail.com\"}}", "memory": "false", "agents": "\"[{'id': '138b02d9-cf1b-4bc0-ab69-e893f5a08a3c', 'role': '\\\"Lead Scraper - Target: {max_leads} leads\\\"\\\\n', 'goal': '\\\"CRITICAL: Extract EXACTLY {max_leads} high-quality leads using the search strategy provided by the user.  Focus on prospects that match the user\\\\'s search criteria and target audience. Use multiple search approaches and continue until you have exactly {max_leads} leads. Do not stop until you reach the target number. Track your progress and ensure you deliver exactly {max_leads} leads.\\\"\\\\n', 'backstory': '\\\"An expert lead researcher with a specific mission: to find exactly {max_leads} leads using the user\\\\'s search strategy.  Uses systematic search strategies across various online sources and platforms.  Tracks progress carefully and never stops until the target is reached.  Implements multiple search approaches to ensure the target is met.\\\"\\\\n', 'cache': True, 'config': None, 'verbose': False, 'allow_delegation': True, 'tools': [SerperDevTool(name='Search the internet with Serper', description=\\\"Tool Name: Search the internet with Serper\\\\nTool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\\\\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\\\", env_vars=[EnvVar(name='SERPER_API_KEY', description='API key for Serper', required=True, default=None)], args_schema=<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, base_url='https://google.serper.dev', n_results=10, save_file=False, search_type='search', country='', location='', locale='')], 'max_iter': 50, 'llm': 'openai/gpt-4o-mini'}, {'id': '8d34f5e2-b415-4b99-9175-51bbc11cd282', 'role': '\\\"Email Address Finder\\\"\\\\n', 'goal': '\\\"Find email addresses for leads using multiple search strategies and sources.  Search across company websites, professional directories, social media, and other online sources  to locate valid email addresses for each lead.\\\"\\\\n', 'backstory': '\\\"An expert email researcher with deep knowledge of various online sources and search techniques.  Specializes in finding email addresses through company websites, professional directories,  social media platforms, and other publicly available sources. Uses multiple search strategies  to maximize the chances of finding valid email addresses.\\\"\\\\n', 'cache': True, 'config': None, 'verbose': False, 'allow_delegation': True, 'tools': [SerperDevTool(name='Search the internet with Serper', description=\\\"Tool Name: Search the internet with Serper\\\\nTool Arguments: {'search_query': {'description': 'Mandatory search query you want to use to search the internet', 'type': 'str'}}\\\\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: 'search' (default), 'news'\\\", env_vars=[EnvVar(name='SERPER_API_KEY', description='API key for Serper', required=True, default=None)], args_schema=<class 'crewai_tools.tools.serper_dev_tool.serper_dev_tool.SerperDevToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, base_url='https://google.serper.dev', n_results=10, save_file=False, search_type='search', country='', location='', locale='')], 'max_iter': 20, 'llm': 'openai/gpt-4o-mini'}, {'id': 'c32455ae-4e80-45b0-bfe7-d585fc16b218', 'role': '\\\"Lead Email Validator\\\"\\\\n', 'goal': '\\\"Validate and filter lead email addresses for deliverability, spam traps, and quality using the email_validator tool\\\"\\\\n', 'backstory': '\\\"An email deliverability specialist with expertise in email validation APIs, spam trap detection, and lead quality assessment.  ALWAYS uses the email_validator tool with ONLY the \\\\'emails\\\\' parameter for bulk validation.  Extracts all email addresses from leads and validates them in batches using the provided tool. The tool expects a JSON string array of email addresses.\\\"\\\\n', 'cache': True, 'config': None, 'verbose': False, 'allow_delegation': True, 'tools': [Tool(name='email_validator', description='Tool Name: email_validator\\\\nTool Arguments: {\\\\'emails\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: \\\\n    Validate email addresses for deliverability and spam issues using EmailListVerify API.\\\\n    \\\\n    Args:\\\\n        emails: JSON string of email addresses for validation\\\\n        \\\\n    Example:\\\\n        ```json\\\\n        {\\\\n            \\\"emails\\\": \\\"[\\\"john@example.com\\\", \\\"jane@example.com\\\"]\\\"\\\\n        }\\\\n        ```\\\\n        \\\\n        Or for single email:\\\\n        ```json\\\\n        {\\\\n            \\\"emails\\\": \\\"[\\\"john.doe@example.com\\\"]\\\"\\\\n        }\\\\n        ```\\\\n    ', env_vars=[], args_schema=<class 'abc.Email_Validator'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, func=<function validate_email at 0x13012b2e0>)], 'max_iter': 2, 'llm': 'openai/gpt-4.1-nano'}, {'id': '12f7e4af-cf73-48a0-b62e-123cf181bdf5', 'role': '\\\"Data Storage Specialist\\\"\\\\n', 'goal': '\\\"CRITICAL: Use Google Sheets tool to save lead data to user\\\\'s Google Workspace.  ALWAYS use the provided tool - never create fake URLs or pretend to save data. ALWAYS wait for the tool response before proceeding.\\\"\\\\n', 'backstory': '\\\"A data storage specialist with expertise in Google Sheets integration.  ALWAYS uses the provided Google Sheets tool to save data to the user\\\\'s account.  Never creates fake URLs or pretends to save data.  Always waits for tool responses before proceeding. Ensures all data is properly stored in the user\\\\'s Google Workspace.\\\"\\\\n', 'cache': True, 'config': None, 'verbose': False, 'allow_delegation': False, 'tools': [Tool(name='google_sheets_saver', description='Tool Name: google_sheets_saver\\\\nTool Arguments: {\\\\'data\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}, \\\\'sheet_name\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}, \\\\'user_id\\\\': {\\\\'description\\\\': None, \\\\'type\\\\': \\\\'str\\\\'}}\\\\nTool Description: \\\\n    Save lead data and campaign information to user\\\\'s Google Sheets.\\\\n    \\\\n    Args:\\\\n        data: JSON string containing data to save\\\\n        sheet_name: Name of the sheet to write to (default: \\\"Leads\\\")\\\\n        user_id: User ID for authentication (default: \\\"default\\\")\\\\n        \\\\n    Example:\\\\n        ```json\\\\n        {\\\\n            \\\"data\\\": \\\"[{\\\"name\\\": \\\"John Doe\\\", \\\"email\\\": \\\"john@example.com\\\", \\\"company\\\": \\\"Tech Corp\\\"}]\\\",\\\\n            \\\"sheet_name\\\": \\\"Leads\\\",\\\\n            \\\"user_id\\\": \\\"user123\\\"\\\\n        }\\\\n        ```\\\\n    ', env_vars=[], args_schema=<class 'abc.Google_Sheets_Saver'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x122423920>, result_as_answer=False, max_usage_count=None, current_usage_count=0, func=<function save_to_google_sheets at 0x130852de0>)], 'max_iter': 2, 'llm': 'openai/gpt-4o-mini'}]\""}, "events": [{"time_unix_nano": 1752420536763271000, "name": "exception", "attributes": {"exception.type": "ValueError", "exception.message": "Missing required template variable 'Template variable 'domain' not found in inputs dictionary' in description", "exception.stacktrace": "Traceback (most recent call last):\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/crewai/task.py\", line 589, in interpolate_inputs_and_add_conversation_history\n    self.description = interpolate_only(\n                       ^^^^^^^^^^^^^^^^^\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/crewai/utilities/string_utils.py\", line 71, in interpolate_only\n    raise KeyError(\nKeyError: \"Template variable 'domain' not found in inputs dictionary\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 589, in use_span\n    yield span\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/mlflow/tracing/fluent.py\", line 478, in start_span\n    yield mlflow_span\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/mlflow/crewai/autolog.py\", line 28, in patched_class_call\n    result = original(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 475, in call_original\n    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 426, in call_original_fn_with_event_logging\n    original_fn_result = original_fn(*og_args, **og_kwargs)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 472, in _original_fn\n    original_result = original(*_og_args, **_og_kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/crewai/crew.py\", line 646, in kickoff\n    self._interpolate_inputs(inputs)\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/crewai/crew.py\", line 1284, in _interpolate_inputs\n    task.interpolate_inputs_and_add_conversation_history(\n  File \"/Users/geethika/Desktop/Lead_Generation_Agent/Lead_Generation_Agent/.venv/lib/python3.12/site-packages/crewai/task.py\", line 593, in interpolate_inputs_and_add_conversation_history\n    raise ValueError(\nValueError: Missing required template variable 'Template variable 'domain' not found in inputs dictionary' in description\n", "exception.escaped": "False"}}], "status": {"message": "ValueError: Missing required template variable 'Template variable 'domain' not found in inputs dictionary' in description", "code": "STATUS_CODE_ERROR"}}]}